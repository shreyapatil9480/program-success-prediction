{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ac09153",
   "metadata": {},
   "source": [
    "\n",
    "# Business Analytics Project: Synthetic Program Data\n",
    "\n",
    "This project showcases an end\u2011to\u2011end analytics workflow suitable for business analysts, program managers, and data analysts.\n",
    "\n",
    "The dataset simulates information about company programs/projects, including budget, duration, team size, complexity, region, stakeholder satisfaction, return on investment (ROI), and a binary indicator for whether the program was deemed a success.\n",
    "\n",
    "In this notebook we'll:\n",
    "\n",
    "1. Explore the data and visualize key relationships.\n",
    "2. Prepare features and build predictive models to estimate program success.\n",
    "3. Discuss next steps for future refinement.\n",
    "\n",
    "The dataset is provided in `synthetic_project_data.csv` located in the `data/` folder of this repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f55b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'data/synthetic_project_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abeed87",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset Description\n",
    "\n",
    "| Column                    | Description                                                   |\n",
    "|---------------------------|---------------------------------------------------------------|\n",
    "| `Budget_Million`          | Total program budget in millions of currency units             |\n",
    "| `Duration_Months`         | Program duration in months                                    |\n",
    "| `Team_Size`               | Number of people involved in the program                      |\n",
    "| `Complexity`              | Categorical indicator of complexity (Low, Medium, High)       |\n",
    "| `Region`                  | Geographic region (North, South, East, West)                  |\n",
    "| `Stakeholder_Satisfaction`| Stakeholder satisfaction rating on a scale of 1\u20135            |\n",
    "| `Success`                 | Binary indicator (1 for success, 0 for failure)               |\n",
    "| `ROI_Million`             | Return on investment in millions of currency units            |\n",
    "\n",
    "This synthetic dataset is generated for illustrative purposes. The relationships between features and the success indicator have been modeled using a logistic function with added noise to reflect real\u2011world variability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ee7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summary statistics\n",
    "summary = data.describe(include='all')\n",
    "print('Summary Statistics:')\n",
    "print(summary)\n",
    "\n",
    "# Histograms for numeric variables\n",
    "numeric_cols = ['Budget_Million', 'Duration_Months', 'Team_Size', 'Stakeholder_Satisfaction', 'ROI_Million']\n",
    "fig, axs = plt.subplots(len(numeric_cols), 1, figsize=(8, 16))\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    sns.histplot(data[col], kde=True, ax=axs[i])\n",
    "    axs[i].set_title(f'Distribution of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Success distribution\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.countplot(x='Success', data=data)\n",
    "plt.title('Success vs Failure Counts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768f385",
   "metadata": {},
   "source": [
    "\n",
    "From the histograms we can examine the distribution of key metrics. For instance, budgets and ROI values span a wide range, while stakeholder satisfaction scores follow a fairly even distribution between 1 and 5. The success indicator is balanced enough to allow for meaningful modeling.\n",
    "\n",
    "The next step is to prepare the data for modeling. We'll start with a simple logistic regression model using just the numerical features, then expand to a more complex model by including categorical variables using one\u2011hot encoding and a random forest classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231feee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select numeric features for a baseline model\n",
    "X = data[['Budget_Million', 'Duration_Months', 'Team_Size', 'Stakeholder_Satisfaction', 'ROI_Million']]\n",
    "y = data['Success']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "preds = log_reg.predict(X_test_scaled)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "print(f\"Logistic Regression Accuracy: {acc:.2f}\")\n",
    "print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd7c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Features and target\n",
    "X_full = data.drop('Success', axis=1)\n",
    "y_full = data['Success']\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = ['Budget_Million', 'Duration_Months', 'Team_Size', 'Stakeholder_Satisfaction', 'ROI_Million']\n",
    "categorical_features = ['Complexity', 'Region']\n",
    "\n",
    "# Preprocess: scale numeric and one\u2011hot encode categorical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define model\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "# Create the pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', rf)\n",
    "                     ])\n",
    "\n",
    "# Split data\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y_full, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "clf.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Predict and evaluate\n",
    "rf_preds = clf.predict(X_test_full)\n",
    "rf_acc = accuracy_score(y_test_full, rf_preds)\n",
    "print(f\"Random Forest Accuracy: {rf_acc:.2f}\")\n",
    "print(classification_report(y_test_full, rf_preds))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_mat = confusion_matrix(y_test_full, rf_preds)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fed60ab",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusions and Next Steps\n",
    "\n",
    "In this notebook we explored a synthetic dataset and built two predictive models:\n",
    "\n",
    "- **Logistic Regression** using only numeric features achieved moderate performance. Scaling numeric features is important for this model and the results provide a baseline.\n",
    "- **Random Forest Classifier** leveraging both numeric and categorical features (via one\u2011hot encoding) achieved higher accuracy and better overall classification metrics, capturing nonlinear relationships and interactions.\n",
    "\n",
    "### Potential Enhancements\n",
    "\n",
    "- **Hyperparameter Tuning**: Explore grid search or randomized search to find optimal model parameters.\n",
    "- **Feature Engineering**: Create additional features, such as budget per team member or duration per complexity level, which might improve model performance.\n",
    "- **Regression Task**: Predict continuous ROI or satisfaction scores using regression algorithms to provide more granular insights.\n",
    "- **Dashboard Creation**: Build an interactive dashboard (e.g., using Plotly Dash or Streamlit) to allow stakeholders to explore the data and model predictions.\n",
    "\n",
    "This project demonstrates an increasing level of complexity by moving from basic descriptive analysis through to more sophisticated modeling. It can serve as a solid example in your portfolio for roles such as business analyst, program manager, or data analyst.\n",
    "\n",
    "If you'd like to expand the project further or adapt it to specific industries or questions, feel free to modify the data generation process or analysis steps.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
